{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Road to Data Science in 50 Days - Day 4\n",
    "***\n",
    "\n",
    "## Statistics for Data Science\n",
    "\n",
    "![](https://hackr.io/blog/statistics-for-data-science/thumbnail/large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we got introduced to inferential statistcs and different types of probability distributions. If you want to learn more about probability such as Conditional probability, bayes theorem (Which we are going to cover ahead when we will learn about a Machine Learning algorithm called Naive Bayes), head to this link which explains it with very good visualizations and examples: https://www.mathsisfun.com/data/probability-events-types.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation\n",
    "\n",
    "In statistics, **estimation** refers to the process by which one makes inferences about a population, based on information obtained from a sample.\n",
    "<div>\n",
    "<img src=\"https://slideplayer.com/slide/12804844/77/images/4/Point+and+Interval+Estimates.jpg\" width=\"600\" height=\"200\">\n",
    "</div>\n",
    "Point Estimate vs. Interval Estimate\n",
    "\n",
    "Statisticians use sample statistics to estimate population parameters. For example, sample means are used to estimate population means; sample proportions, to estimate population proportions.\n",
    "\n",
    "An estimate of a population parameter may be expressed in two ways:\n",
    "\n",
    "* Point estimate. A point estimate of a population parameter is a single value of a statistic. For example, the sample mean x is a point estimate of the population mean Œº. Similarly, the sample proportion p is a point estimate of the population proportion P.\n",
    "\n",
    "\n",
    "* Interval estimate. An interval estimate is defined by two numbers, between which a population parameter is said to lie. For example, a < x < b is an interval estimate of the population mean Œº. It indicates that the population mean is greater than a but less than b.\n",
    "\n",
    "Types\n",
    "Estimators can be described in several ways (click on the bold word for the main article on that term):\n",
    "\n",
    "* <a href=\"https://www.statisticshowto.com/what-is-bias/\"><b>Biased</b></a>: a statistic that is either an overestimate or an underestimate.\n",
    "\n",
    "* <a href=\"https://www.statisticshowto.com/efficient-estimator-efficiency/\"><b>Efficient</b></a>: a statistic with small variances (the one with the smallest possible variance is also called the ‚Äúbest‚Äù). Inefficient estimators can give you good results as well, but they usually requires much larger samples.\n",
    "\n",
    "* <a href=\"https://www.statisticshowto.com/scale-invariance/\"><b>Invariant</b></a>: statistics that are not easily changed by transformations, like simple data shifts.\n",
    "\n",
    "* <a href=\"https://www.statisticshowto.com/shrinkage-estimator/\"><b>Shrinkage</b></a>: a raw estimate that‚Äôs improved by combining it with other information. See also: The James-Stein estimator.\n",
    "\n",
    "* <a href=\"https://www.statisticshowto.com/sufficient-statistic/\"><b>Sufficient</b></a>: a statistic that estimates the population parameter as well as if you knew all of the data in all possible samples.\n",
    "\n",
    "* <a href=\"https://www.statisticshowto.com/unbiased/\"><b>UnBiased</b></a>: an accurate statistic that neither underestimates nor overestimates.\n",
    "\n",
    "#### Confidence Intervals\n",
    "\n",
    "Statisticians use a confidence interval to express the precision and uncertainty associated with a particular sampling method. A confidence interval consists of three parts.\n",
    "\n",
    "* A confidence level.\n",
    "* A statistic.\n",
    "* A margin of error.\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30111058/sampling_3.png)\n",
    "\n",
    "The confidence level describes the uncertainty of a sampling method. The statistic and the margin of error define an interval estimate that describes the precision of the method. The interval estimate of a confidence interval is defined by the sample statistic + margin of error.\n",
    "\n",
    "For example, suppose we compute an interval estimate of a population parameter. We might describe this interval estimate as a 95% confidence interval. This means that if we used the same sampling method to select different samples and compute different interval estimates, the true population parameter would fall within a range defined by the sample statistic + margin of error 95% of the time.\n",
    "\n",
    "Confidence intervals are preferred to point estimates, because confidence intervals indicate \n",
    "(a) the precision of the estimate and (b) the uncertainty of the estimate.\n",
    "\n",
    "Formally, Confidence Interval is defined as: \n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30111025/image_11.png)\n",
    "\n",
    "whereas,  **XÃÑ** = the sample mean\n",
    "\n",
    "**Z<subscript>a/2</subscript>**= Z value for desired confidence level Œ±\n",
    "\n",
    "**œÉ** = the population standard deviation\n",
    "\n",
    "For an alpha value of 0.95 i.e 95% confidence interval, z=1.96.\n",
    "\n",
    "\n",
    "#### Confidence Level\n",
    "The probability part of a confidence interval is called a confidence level. The confidence level describes the likelihood that a particular sampling method will produce a confidence interval that includes the true population parameter.\n",
    "\n",
    "Here is how to interpret a confidence level. Suppose we collected all possible samples from a given population, and computed confidence intervals for each sample. Some confidence intervals would include the true population parameter; others would not. A 95% confidence level means that 95% of the intervals contain the true population parameter; a 90% confidence level means that 90% of the intervals contain the population parameter; and so on.\n",
    "\n",
    "#### Margin of Error\n",
    "In a confidence interval, the range of values above and below the sample statistic is called the margin of error.\n",
    "\n",
    "For example, suppose the local newspaper conducts an election survey and reports that the independent candidate will receive 30% of the vote. The newspaper states that the survey had a 5% margin of error and a confidence level of 95%. These findings result in the following confidence interval: We are 95% confident that the independent candidate will receive between 25% and 35% of the vote.\n",
    "\n",
    "Note: Many public opinion surveys report interval estimates, but not confidence intervals. They provide the margin of error, but not the confidence level. To clearly interpret survey results you need to know both! We are much more likely to accept survey findings if the confidence level is high (say, 95%) than if it is low (say, 50%).\n",
    "\n",
    "\n",
    "Interesting points to note about Confidence Intervals:\n",
    "\n",
    "* Confidence Intervals can be built with difference degrees of confidence suitable to a user‚Äôs needs like 70 %, 90% etc.\n",
    "* Greater the sample size, smaller the Confidence Interval, i.e more accurate determination of population mean from the sample means.\n",
    "* There are different confidence intervals for different sample means. For example, a sample mean of 40 will have a difference confidence interval from a sample mean of 45.\n",
    "* By 95% Confidence Interval, we do not mean that ‚Äì The probability of a population mean to lie in an interval is 95%. Instead, 95% C.I means that 95% of the Interval estimates will contain the population statistic.\n",
    "\n",
    "*Many people do not have right knowledge about confidence interval and often interpret it incorrectly. So, I would like you to take your time visualizing the 4th argument and let it sink in.*\n",
    "\n",
    "***\n",
    "\n",
    "Too many technical terms has been introduced. Let's test our understanding.\n",
    "\n",
    "Which of the following statements is true.\n",
    "\n",
    "I. When the margin of error is small, the confidence level is high. <br>\n",
    "II. When the margin of error is small, the confidence level is low.<br>\n",
    "III. A confidence interval is a type of point estimate.<br>\n",
    "IV. A population mean is an example of a point estimate.<br>\n",
    "\n",
    "(A) I only<br>\n",
    "(B) II only<br>\n",
    "(C) III only<br>\n",
    "(D) IV only.<br>\n",
    "(E) None of the above.<br>\n",
    "\n",
    "**Solution**:\n",
    "The correct answer is (E). The confidence level is not affected by the margin of error. When the margin of error is small, the confidence level can low or high or anything in between. A confidence interval is a type of interval estimate, not a type of point estimate. A population mean is not an example of a point estimate; a sample mean is an example of a point estimate.\n",
    "\n",
    "\n",
    "#### Practical example\n",
    "\n",
    "Calculate the 95% confidence interval for a sample mean of 40 and sample standard deviation of 40 with sample size equal to 100.\n",
    "\n",
    "Solution:\n",
    "\n",
    "We know, z-value for 95% C.I is 1.96. Hence, Confidence Interval (C.I) is calculated as:\n",
    "\n",
    "C.I= [{x(bar) ‚Äì (z*s/‚àön)},{x(bar) ‚Äì (z*s/‚àön)}]\n",
    "\n",
    "C.I = [{40-(1.96*40/10},{ 40+(1.96*40/10)}]\n",
    "\n",
    "C.I = [32.16, 47.84]\n",
    "\n",
    "\n",
    "#### What is the Standard Error?\n",
    "\n",
    "The standard error is an estimate of the standard deviation of a statistic. This lesson shows how to compute the standard error, based on sample data.\n",
    "\n",
    "The standard error is important because it is used to compute other measures, like confidence intervals and margins of error.\n",
    "\n",
    "Refer to this link to learn more about the notations and formulas: https://stattrek.com/estimation/standard-error.aspx?tutorial=\n",
    "\n",
    "***\n",
    "\n",
    "Now that we have been introduced to a lot of technical terms, we enter the territory of one of the most important and critical part of statistics for researchers and data science in general i.e. **Hypothesis Testing**\n",
    "\n",
    "# 1. Hypothesis Testing\n",
    "\n",
    "Before I get into the theoretical explanation, let us understand Hypothesis Testing by using a simple example.\n",
    "\n",
    "**Example**: Class 8th has a mean score of 40 marks out of 100. The principal of the school decided that extra classes are necessary in order to improve the performance of the class. The class scored an average of 45 marks out of 100 after taking extra classes. Can we be sure whether the increase in marks is a result of extra classes or is it just random?\n",
    "\n",
    "![](https://miro.medium.com/max/1018/0*p3p9bovzJXb4bjdO.gif)\n",
    "\n",
    "Hypothesis testing lets us identify that. It lets a sample statistic to be checked against a population statistic or statistic of another sample to study any intervention etc. Extra classes being the intervention in the above example.\n",
    "\n",
    "Hypothesis testing is defined in two terms ‚Äì *Null Hypothesis* and *Alternate Hypothesis*.\n",
    "\n",
    "* **Null Hypothesis** being the sample statistic to be equal to the population statistic. For eg: The Null Hypothesis for the above example would be that the average marks after extra class are same as that before the classes.\n",
    "\n",
    "\n",
    "* **Alternate Hypothesis** for this example would be that the marks after extra class are significantly different from that before the class.\n",
    "\n",
    "Hypothesis Testing is done on different levels of confidence and makes use of z-score to calculate the probability. So for a 95% Confidence Interval, anything above the z-threshold for 95% would reject the null hypothesis.\n",
    "\n",
    "Points to be noted:\n",
    "\n",
    "1. We cannot accept the Null hypothesis, only reject it or fail to reject it.\n",
    "2. As a practical tip, Null hypothesis is generally kept which we want to disprove. For eg: You want to prove that students performed better after taking extra classes on their exam. The Null Hypothesis, in this case, would be that the marks obtained after the classes are same as before the classes.\n",
    "\n",
    "# 2. Types of Errors in Hypothesis Testing\n",
    "\n",
    "Now we have defined a basic Hypothesis Testing framework. It is important to look into some of the mistakes that are committed while performing Hypothesis Testing and try to classify those mistakes if possible.\n",
    "\n",
    "Now, look at the Null Hypothesis definition above. What we notice at the first look is that it is a statement subjective to the tester like you and me and not a fact. That means there is a possibility that the Null Hypothesis can be true or false and we may end up committing some mistakes on the same lines.\n",
    "\n",
    "There are two types of errors that are generally encountered while conducting Hypothesis Testing.\n",
    "\n",
    "* **Type I error**: Look at the following scenario ‚Äì A male human tested positive for being pregnant. Is it even possible? This surely looks like a case of False Positive. More formally, it is defined as the incorrect rejection of a True Null Hypothesis. The Null Hypothesis, in this case, would be ‚Äì Male Human is not pregnant.\n",
    "\n",
    "* **Type II error**: Look at another scenario where our Null Hypothesis is ‚Äì A male human is pregnant and the test supports the Null Hypothesis.  This looks like a case of False Negative. More formally it is defined as the acceptance of a false Null Hypothesis.\n",
    "\n",
    "The below image will summarize the types of error :\n",
    "\n",
    "![](http://www.personal.ceu.hu/students/08/Olga_Etchevskaia/images/errors.jpg)\n",
    "\n",
    "Another very impressive examples is: \n",
    "\n",
    "![](https://i.redd.it/ob8za0yst6f21.png)\n",
    "\n",
    "\n",
    "# 3. T-Tests\n",
    "\n",
    "T-tests are very much similar to the z-scores, the only difference being that instead of the Population Standard Deviation, we now use the Sample Standard Deviation. The rest is same as before, calculating probabilities on basis of t-values.\n",
    "\n",
    "The Sample Standard Deviation is given as:\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30121520/eq_2.png)\n",
    "\n",
    "where n-1 is the Bessel‚Äôs correction for estimating the population parameter.\n",
    "\n",
    "Another difference between z-scores and t-values are that t-values are dependent on Degree of Freedom of a sample. Let us define what degree of freedom is for a sample.\n",
    "\n",
    "**The Degree of Freedom** ‚Äì  It is the number of variables that have the choice of having more than one arbitrary value. For example, in a sample of size 10 with mean 10, 9 values can be arbitrary but the 1oth value is forced by the sample mean.\n",
    "\n",
    "Points to note about the t-tests:\n",
    "\n",
    "* Greater the difference between the sample mean and the population mean, greater the chance of rejecting the Null Hypothesis. Why? (We discussed this above.)\n",
    "* Greater the sample size, greater the chance of rejection of Null Hypothesis.\n",
    "\n",
    "# 4. Different types of t-tests\n",
    "\n",
    "### 4.1 1-sample T-test\n",
    "\n",
    "This is the same test as we described above. This test is used to:\n",
    "\n",
    "* Determine whether the mean of a group differs from the specified value.\n",
    "* Calculate a range of values that are likely to include the population mean.\n",
    "\n",
    "For eg: A pizza delivery manager may perform a 1-sample t-test whether their delivery time is significantly different from that of the advertised time of 30 minutes by their competitors.\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30122221/eq_3.png)\n",
    "\n",
    "where, X(bar) = sample mean\n",
    "\n",
    "Œº = population mean\n",
    "\n",
    "s = sample standard deviation\n",
    "\n",
    "N = sample size\n",
    "\n",
    "### 4.2 Paired t-test\n",
    "\n",
    "Paired t-test is performed to check whether there is a difference in mean after a treatment on a sample in comparison to before. It checks whether the Null hypothesis: The difference between the means is Zero, can be rejected or not.\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30230329/Screenshot-13.png)\n",
    "\n",
    "The above example suggests that the Null Hypothesis should not be rejected and that there is no significant difference in means before and after the intervention since p-value is not less than the alpha value (o.o5) and t stat is not less than t-critical. \n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30122821/eq_4.png)\n",
    "\n",
    "where, d (bar) = mean of the case wise difference between before and after,\n",
    "\n",
    "Sd = standard deviation of the difference\n",
    "\n",
    "n = sample size.\n",
    "\n",
    "### 4.3 2-sample t-test\n",
    "\n",
    "This test is used to determine:\n",
    "\n",
    "* Determine whether the means of two independent groups differ.\n",
    "* Calculate a range of values that is likely to include the difference between the population means.\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30123537/eq_41.png)\n",
    "\n",
    "The above formula represents the 2 sample t-test and can be used in situations like to check whether two machines are producing the same output. The points to be noted for this test are:\n",
    "\n",
    "1. The groups to be tested should be independent.\n",
    "2. The groups‚Äô distribution should not be highly skewed.\n",
    "where, \n",
    "X1 (bar) = mean of the first group\n",
    "\n",
    "S1 = represents 1st group sample standard deviation\n",
    "\n",
    "N1 = represents the 1st group sample size.\n",
    "\n",
    "### 4.4 Practical example\n",
    "\n",
    "We will understand how to identify which t-test to be used and then proceed on to solve it. The other t-tests will follow the same argument.\n",
    "\n",
    "**Example**: A population has mean weight of 68 kg. A random sample of size 25 has a mean weight of 70 with standard deviation =4. Identify whether this sample is representative of the population?\n",
    "\n",
    "**Step 0: Identifying the type of t-test**\n",
    "\n",
    "Number of samples in question = 1\n",
    "\n",
    "Number of times the sample is in study = 1\n",
    "\n",
    "Any intervention on sample = No\n",
    "\n",
    "Recommended t-test = 1- sample t-test.\n",
    "\n",
    "Had there been 2 samples, we would have opted for 2-sample t-test and if there would have been 2 observations on the same sample, we would have opted for paired t-test.\n",
    "\n",
    "\n",
    "**Step 1: State the Null and Alternate Hypothesis**\n",
    "\n",
    "* Null Hypothesis: The sample mean and population mean are same.\n",
    "\n",
    "* Alternate Hypothesis: The sample mean and population mean are different.\n",
    "\n",
    " \n",
    "**Step 2: Calculate the appropriate test statistic**\n",
    "\n",
    "df = 25-1 =24\n",
    "\n",
    "t= (70-68)/(4/‚àö25) = 2.5\n",
    "\n",
    "Now, for a 95% confidence level, t-critical (two-tail) for rejecting Null Hypothesis for 24 d.f is 2.06 . Hence, we can reject the Null Hypothesis and conclude that the two means are different.\n",
    "\n",
    "You can use the t-test calculator <a href=\"https://www.danielsoper.com/statcalc/calculator.aspx?id=98\">here</a>\n",
    "\n",
    "# 5. ANOVA\n",
    "\n",
    "ANOVA (Analysis of Variance) is used to check if at least one of two or more groups have statistically different means. Now, the question arises ‚Äì Why do we need another test for checking the difference of means between independent groups? Why can we not use multiple t-tests to check for the difference in means?\n",
    "\n",
    "The answer is simple. Multiple t-tests will have a compound effect on the error rate of the result. Performing t-test thrice will give an error rate of ~15% which is too high, whereas ANOVA keeps it at 5% for a 95% confidence interval.\n",
    "\n",
    "To perform an ANOVA, you must have a continuous response variable and at least one categorical factor with two or more levels. ANOVA requires data from approximately normally distributed populations with equal variances between factor levels. However, ANOVA procedures work quite well even if the normality assumption has been violated unless one or more of the distributions are highly skewed or if the variances are quite different.\n",
    "\n",
    "ANOVA is measured using a statistic known as F-Ratio. It is defined as the ratio of Mean Square (between groups) to the Mean Square (within group).\n",
    "\n",
    "Mean Square (between groups) = Sum of Squares (between groups) / degree of freedom (between groups)\n",
    "\n",
    "Mean Square (within group) = Sum of Squares (within group) / degree of freedom (within group)\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/20071114/Screenshot-from-2017-01-20-04-38-39.png)\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30124859/eq_5-300x107.png)\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/30124918/eq_6-300x118.png)\n",
    "\n",
    "Here, **p** = represents the number of groups\n",
    "\n",
    "**n** = represents the number of observations in a group\n",
    "\n",
    "**Xj (bar)** =  represents the mean of a particular group\n",
    "\n",
    "**X (bar)** = represents the mean of all the observations\n",
    "\n",
    "Now, let us understand the degree of freedom for within group and between groups respectively.\n",
    "\n",
    "Between groups : If there are k groups in ANOVA model, then k-1 will be independent. Hence, k-1 degree of freedom.\n",
    "\n",
    "Within groups : If N represents the total observations in ANOVA (‚àën over all groups) and k are the number of groups then, there will be k fixed points. Hence, N-k degree of freedom.\n",
    "\n",
    "### 5.1 Steps to perform ANOVA\n",
    "\n",
    "1. Hypothesis Generation\n",
    "<ul>\n",
    "<li>Null Hypothesis : Means of all the groups are same </li>\n",
    "<li>Alternate Hypothesis : Mean of at least one group is different</li> </ul>\n",
    "2. Calculate within group and between groups variability\n",
    "3. Calculate F-Ratio\n",
    "4. Calculate probability using F-table\n",
    "5. Reject/fail to Reject Null Hypothesis\n",
    "\n",
    "There are various other forms of ANOVA too like Two-way ANOVA, MANOVA, ANCOVA etc. but One-Way ANOVA suffices the requirements of this course.\n",
    "\n",
    "Practical applications of ANOVA in modeling are:\n",
    "\n",
    "1. Identifying whether a categorical variable is relevant to a continuous variable.\n",
    "2. Identifying whether a treatment was effective to the model or not.\n",
    "\n",
    "### 5.2 Practical Example\n",
    "\n",
    "Suppose there are 3 chocolates in town and their sweetness is quantified by some metric (S). Data is collected on the three chocolates. You are given the task to identify whether the mean sweetness of the 3 chocolates are different. The data is given as below:\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/01/20071549/Screenshot-from-2017-01-20-04-43-12.png)\n",
    "\n",
    "Here, first we have calculated the sample mean and sample standard deviation for you.\n",
    "Now we will proceed step-wise to calculate the F-Ratio (ANOVA statistic).\n",
    "\n",
    "**Step 1: Stating the Null and Alternate Hypothesis**\n",
    "\n",
    "**Null Hypothesis**: Mean sweetness of the three chocolates are same.\n",
    "\n",
    "**Alternate Hypothesis**: Mean sweetness of at least one of the chocolates is different.\n",
    "\n",
    "**Step 2: Calculating the appropriate ANOVA statistic**\n",
    "\n",
    "In this part, we will be calculating SS(B), SS(W), SS(T) and then move on to calculate MS(B) and MS(W). The thing to note is that,\n",
    "\n",
    "Total Sum of Squares [SS(t)] = Between Sum of Squares [SS(B)] + Within Sum of Squares [SS(W)].\n",
    "\n",
    "So, we need to calculate any two of the three parameters using the data table and formulas given above.\n",
    "\n",
    "As, per the formula above, we need one more statistic i.e Grand Mean denoted by X(bar) in the formula above.\n",
    "\n",
    "**X bar** = (643+655+702+469+427+525+484+456+402)/9 = 529.22\n",
    "\n",
    "**SS(B)**=[3*(666.67-529.22)^2]+ [3*(473.67-529.22)^2]+[3*(447.33-529.22)^2] = 86049.55\n",
    "\n",
    "**SS (W)** = [(643-666.67)^2+(655-666.67)^2+(702-666.67)^2] + [(469-473.67)^2+(427-473.67)^2+(525-473.67)^2] + [(484-447.33)^2+(456-447.33)^2+(402-447.33)^2]= 10254\n",
    "\n",
    "**MS(B)** = SS(B) / df(B) = 86049.55 / (3-1) = 43024.78\n",
    "\n",
    "**MS(W)** = SS(W) / df(W) = 10254/(9-3) = 1709\n",
    "\n",
    "**F-Ratio** = MS(B) / MS(W) = 25.17 .\n",
    "\n",
    "Now, for a 95 % confidence level, F-critical to reject Null Hypothesis for degrees of freedom(2,6) is 5.14 but we have 25.17 as our F-Ratio.\n",
    "\n",
    "So, we can confidently reject the Null Hypothesis and come to a conclusion that at least one of the chocolate has a mean sweetness different from the others.\n",
    "\n",
    "You can use the F-calculator <a href=\"http://stattrek.com/online-calculator/f-distribution.aspx\">here</a>.\n",
    "\n",
    "**Note**: ANOVA only lets us know the means for different groups are same or not. It doesn‚Äôt help us identify which mean is different.To know which group mean is different, we can use another test know as Least Significant Difference Test.\n",
    "\n",
    "# 6. Chi-square Goodness of Fit Test\n",
    "\n",
    "Sometimes, the variable under study is not a continuous variable but a categorical variable. Chi-square test is used when we have one single categorical variable from the population.\n",
    "\n",
    "Let us understand this with help of an example. Suppose a company that manufactures chocolates, states that they manufacture 30% dairy milk, 60% temptation and 10% kit-kat. Now suppose a random sample of 100 chocolates has 50 dairy milk, 45 temptation and 5 kitkats. Does this support the claim made by the company?\n",
    "\n",
    "Let us state our Hypothesis first.\n",
    "\n",
    "* Null Hypothesis: The claims are True\n",
    "\n",
    "* Alternate Hypothesis: The claims are False.\n",
    "\n",
    "Chi-Square Test is given by:\n",
    "\n",
    "![](http://www.statisticshowto.com/wp-content/uploads/2013/09/chi-square-formula.jpg)\n",
    "\n",
    "where, **Oi** = sample or observed values\n",
    "\n",
    "**Ei** = population values\n",
    "\n",
    "The summation is taken over all the levels of a categorical variable.\n",
    "\n",
    "**Ei = [n * Pi]**  Expected value of a level (i) is equal to the product of sample size and percentage of it in the population.\n",
    "\n",
    "\n",
    "Let us now calculate the Expected values of all the levels.\n",
    "\n",
    "E (dairy milk)= 100 * 30% = 30\n",
    "\n",
    "E (temptation) = 100 * 60% =60\n",
    "\n",
    "E (kitkat) = 100 * 10% = 10\n",
    "\n",
    "Calculating chi-square = [(50-30)^2/30+(45-60)^2/60+(5-10)^2/10] =19.58\n",
    "\n",
    " \n",
    "\n",
    "Now, checking for p (chi-square >19.58) using <a href=\"http://stattrek.com/online-calculator/chi-square.aspx\">chi-square calculator</a>, we get p=0.0001. This is significantly lower than the alpha(0.05).\n",
    "\n",
    "*So we reject the Null Hypothesis.*\n",
    "\n",
    "# 7. Correlation\n",
    "\n",
    "Correlation is used to test relationships between quantitative variables. In other words, it‚Äôs a measure of how things are related. The study of how variables are correlated is called correlation analysis.\n",
    "\n",
    "Some examples of data that have a high correlation:\n",
    "\n",
    "* Your caloric intake and your weight.\n",
    "* Your eye color and your relatives‚Äô eye colors.\n",
    "* The amount of time your study and your GPA.\n",
    "\n",
    "Some examples of data that have a low correlation (or none at all):\n",
    "\n",
    "* Your sexual preference and the type of cereal you eat.\n",
    "* A dog‚Äôs name and the type of dog biscuit they prefer.\n",
    "* The cost of a car wash and how long it takes to buy a soda inside the station.\n",
    "\n",
    "Correlations are useful because if you can find out what relationship variables have, you can make predictions about future behavior. Knowing what the future holds is very important in the social sciences like government and healthcare. Businesses also use these statistics for budgets and business plans.\n",
    "\n",
    "### 7.1 The Correlation Coefficient\n",
    "\n",
    "A correlation coefficient is a way to put a value to the relationship. Correlation coefficients have a value of between -1 and 1. A ‚Äú0‚Äù means there is no relationship between the variables at all, while -1 or 1 means that there is a perfect negative or positive correlation (negative or positive correlation here refers to the type of graph the relationship will produce).\n",
    "\n",
    "![](https://www.statisticshowto.com/wp-content/uploads/2012/10/pearson-2-small.png)\n",
    "\n",
    "![](https://www.mathsisfun.com/data/images/correlation-examples.svg)\n",
    "\n",
    "### 7.2 Types\n",
    "\n",
    "The most common correlation coefficient is the Pearson Correlation Coefficient. It‚Äôs used to test for linear relationships between data. In AP stats or elementary stats, the Pearson is likely the only one you‚Äôll be working with. However, you may come across others, depending upon the type of data you are working with. For example, Goodman and Kruskal‚Äôs lambda coefficient is a fairly common coefficient. It can be symmetric, where you do not have to specify which variable is dependent, and asymmetric where the dependent variable is specified.\n",
    "\n",
    "### 7.3 Correlation vs Covariance\n",
    "\n",
    "This has been explained very well by one of my connection on Linkedin - <a href=\"https://www.linkedin.com/in/chayankathuria/\">Chayan Kathuria</a>\n",
    "\n",
    "**Correlation and Covariance** are often confused with each other. They are similar but tell different characteristics of the data. ‚ÅâÔ∏è\n",
    "\n",
    "Correlation and Covariance both the terms measure the relationship and the dependency between two variables. üí°\n",
    "\n",
    "Covariance defines the direction of the variance or the relationship between 2 variables. If Covariance is 0, it means that the variables have no variance with respect to each other. This would mean they are not related and provide completely different information about data.\n",
    "\n",
    "If it is positive, it means that one variable increases as the other increases (directly proportional) and if it is negative, then one of the variables decreases as the other increases (inversely proportional).üìà\n",
    "\n",
    "Correlation, on the other hand, also defines the magnitude of the relation between 2 variables. Correlation is nothing but the covariance divided by the standard deviations of the variables. Hence, the value of correlation lies between -1 and 1. üìâ\n",
    "\n",
    "-1 being a complete inverse proportionality and 1 being a complete direct proportionality. And such variables won't add any more information to the data.\n",
    "\n",
    "![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAdoAAABqCAMAAAAsh2BcAAAB1FBMVEX///9vb2/i4uKjo6PZ9v/fu4JIcZzu3K3y///8//+avOLN9P/v9e9Zk73z+v/q////89KMjIxwXmXd7N3Z8P////f/8sN1d3X/+N5yunJ/qMfn1bHcuJdkos709PSRupGt0OP///C9kFal2/np1MSy3eKieVT25Mna2+L//+r36+QAAADfw5So2f/I5/+GxOpAYI1TWXX/4b+usrXrvpTMomHCmYFup27Uxrqrq7XNrJmzeEuAruL//96YaE3GuruDj5WBlLRtdol1cmW92r1dWmikxaR5hKFon9WTeGrMlmjDp29Ojch3Uj54utZIdrHa4vYAS4n//9ArAABjUkZ8WlKunJhQAADf/+hATnl1QgCMXTWbin92TlLEq4KVXypLboBaSmeazJqDvIPO//8AABzan1wYN1hHSllHMjarmn/nqXK4scwxK0FkaptPpE8NZJljLwA+YH0AMmx4SkNYe5cASXlmm68AAEu6g2aSfIF7V25rJQBVOjNsjIppSCI+M1iMSAAAMHiygzKdZwm6dTWGhGtFHgAAACkAFXBqAAAnABMAIF1uOyoAgABaQioiACMAADctGwA6HBkvFlEGHjdNJ1M7HzZBACyBMwCOi1ZshmcWCidZAAAQSElEQVR4nO2d+UPayN/HJ8phoBCCDCAgmyA3iIhIFQ8URUS03tSrXq3VXtrDbW273bbf3e69+72P53n+2WcmCQhIWX0UdXnm9QNOJnPEvPOZzJkBgEAgEAgEAoFAIBAIBAKBcF6cjV2NBr+s4jlrmgEA9nShEMDZ1dUrhRJ9/MjDYBvS5gM3j46ONl/KJRNOA3TvcQ3W1PftlU5GvzTgIP6PAZUWeN4/52gpkv/jD5wW9vzHpQVBRV7bG2Nj2y13b1zOdRN+D7jxEtkl4FcqSav8IFmpdV4FgE1VdMr6lxCAOSw8cEzTRSdaiN1eE7oDoqbyfiRzQ4OXRj8NXgC9DVoAP45LoczvNXS8WFmge28BMU5wRh5wRSeItNeF/zq6J/z1zQD+YTp3+1VTLLCrAubVp1qg3OHywfpmc6rSiH1PncOii1/VFJktkfaaMDf/p6a8u3uWBrr5STAxKwNwDRXTE0cz+XPBQH9ZzGBAkY/Z96P22J9Ie00okpb/CRe/n44YY6ADeNI0gH0vDPlw2cB4WUxloC3vdBwVVa+JtNcE/vafGMmpFNS7H1CDb2bp1+gNXCRtXPXtLFMas+9FwVTv//XesT+R9rrwSapGAfscKouRTEcMsP7cJTRnX/8iFciobpzdDZXEwxWrvPs+sdrriPmZ0PgBVhX49hfk+qRBmq6Khe2jI9FqcQ0qMl9ajbIWHW/MkmpUDYHa6qcbPnfGPLWnamiIWWjgef/UG09iA5SLhe3cfAfueFqZRu0g2/wLL/ZU/qygcXIfA5Z8jgO/WorSI9KemTjLmkLOyt2BSCBTu22IZVkV8LxhWfGuR9Axy9EAn5iJWT4TE4CexsZGDjt8ucbHgg/0imbomBW6IXtlwNPY1dWLi2dPVwaV4H50KMbB+TxRF6VGpD0j/mebBqDTByp2B6Ibfge9CSN/C7xCkhgDrZKv81nAhf7AiZdeAB3jdOW4VfANljd5UGq5sseLXy0pqom0Z8O/IjQifRW7A9HdHRTUjM4/RU2W7LEcnnkcjX+D36a+X2+dPV/PVFlHBbAlS6tTwOwulZ9Ieza+2TnuDuQTXb1YsITB36U1J7ROjo7uivWdKGq/xCaL4mVxT8M6J8b9saz5cirKbfQEPYbSYyLtmeB/+kWUBVWWzCOWnmdfypzuwKv3O8n3gVffH8m+CYv9DtDxV3a4uNw1rxzJIpKPbl54PKBdokbXeiwtyqnCOwDGQyc9Bcxs9ccoqApyJSnFpJSslpJ87EK+ZVkXAgvohpukkMVhCunQyFn1Ui4OY+C4efHNNBC6A323w3yjwTqvMaf9X+Utld/4QV0SMzL/PCkZqxTKxopYqlep/88UpFUmWTZ5lkwG9Oqq5+Wa0mPobqt0wqlnv5s+GbivrejIGMY3Rb7LHnIVnj5Hxymv+AKYm5/Ndweab+NX26cjRnRYsSnqbud7AXULfwuXPvrZQP5tid7XJ/4Ne8MFcZxkXloe1+zsME51yqL9NJ8J2SjK4suwyYdtEYpKMusmKhUC2BPEqS01cI6MCDVto9600A88+hQnBDYtDGdSBk+GSsnkrXIVCt9pcGZSHPBnTH+X1AqmTFtqnMmbEK7VteN8V3eThhhFcTrKNNKPAlN/x9mmUbYpJk5lFIK0GgAHORBDVxPjgC5tHYYPKX3It7KXXrfAGLXPKCnTQnlt42LhfyrqDsSK3v/hXiVpfW9C8kDp4xr5uUjaJlBGQ+PF0HWc5PZdca6FUjAMZRgEFfCtIYIfK9+dpal2IJhPn8sxDh61BsPoGjxhYNz3bclEqzW+kOn0S3dCZn0zCuzoN+7K7uMK4KNb8tZuVFt8fcunl/neLg22H1vtUxAML701RIVn1/pgiDUAuVCx1HXObYV8h/cG24C7kK01TEtWi25Vd8d6K5BblNPgUX8Qx1cqaGS1ck0QWf6kclYKWjscedtrkLoDf6SLpDXfFgtk4antK20gRXaOpZ3Gf9BzLzBcowJ59OBmS8s2kmgZ35KghZ7bYrKWiTbQox/5x9KiGgli1pseuIT7J8eiyXdN1LBR0aQTpQ0zOn1ziuEHXThwu7GT6W41Z6gFUdoJDW18YqKSOMRxgYwFmLBIx3a7rZPBFhmnRpbnOmW+KZeeQdnq8tneAsfSOm45NilKhXLTy+Qafg0ZNJ2/NOO+EqXc+XsVyfNhfvZCeHbiHPj2BcrqYysYkKRF/w78KIgGMhwOuvKi+Foif+Ekl+f2yUZqDcgXyHADPW8J6ywdnaY9C2Ht3AcGWS1Wi9tox+aD7591GYXxdKKfgQ+yyIOCtAyy2i1+Sg37OrC0lu5+yWqVYRrwegNIIPvnV47ftfJJEHnwHD+tfI4BkWVGPg2Ms03IarG0amTiK66NNjFbZKHRp5K0kU6ZzQJ4L4j+cxIlgmLJFTTKDVntLJCPIzuutbSAdwcsiQTWzux+0bU23ATX5596gf9hQIMaH1nU+IG273e6tAD2vA/scPBbcXwV9mQCz72ifcqPaluySBSqUei9RXHASe03CY8kiFKm9FJOhmrIOhM15LJxuN8alSEq9JpFP0pqKI1vIqq8mhtl5kwy5BMCm3sZG2deo4Y4q8rK2ZDBhmCGGkaVLtNQvoZMUfgtNCiWTyjJL9F9eJg02FCSA70Mn5MJgXXoFY+zhcgfNx9xvE50T+JUcgbANwZULUYv2KHHtCeTXseXlqYjFhrlX+tb1pBIJISBGN6b8GLRvF4krdebQNKaD1Wih1b847X7e9L4vQMbvIIvpq+1WvIXxpW1az36e78f6I+Hcres4wA4yyt28nCNXq5lXJm0J/7jOiH6fKb4ELotZQ0dcdrpJUB6oy4aP1f1NP/4ci6DSFvHEGmvNXGxL5LLH8M14ThZvSNQhEh7jfHf3jVRuFugMOkt8Ny0gPz2T/RmVYBIe36aa7S4xv8M1big+7i+ad1BrcCB1CmrYUTa8zNWo3v4cRb/2l7mW+qer4Tejw3N6WZpEGnPT42kHZgXZmOsv8z3ryl3cFcAXCXSXho1kta4g+dTmb8qrBYQOygjO5+ZllUOkfb81EhaHo/YQ8dsoe/Kiqes+lc11SIVQaQ9P7V613p+3WRTvceVYWidT373nDttdCLt+amVtBjptZpdXjJxxf62J5wnWb0JRKQ9P7WUNs/Eq7IRrWwH/7hqdar5gEh7bi5D2mD56L18vOfzI9PNN2/e3CbKnpPRUSxtre+jszfZUzq11LZZ3WgJ5+fgxlhzc0tt83AOa21lg6DOodN0NhLOw+j2WPPd2hlt5U7M9a705Yzn//+m5e7Y3dqlfiJp4Sly1n6eEAHZ1W8HNfz41s3y3L6oXV6Ecu6O1TBxIm3dQqStW4i0dQuRtm4h0tYtRNrq8F6v90S3nFKareDXlq/mBkCXKnTQwobPd+jBBq0QvzxlvMgS4mUgcKZStLNApK2Kx9TblWkr9w1KC5grLb3WpQpdAsbOz/cOwPuTtLLzxDQ0UdrYNOAXTzkj4vMQaasB+wTxbPqUZWDKlPxvKsXEqC21UmGPUe86+JW9dFbDZ6gPBuUT05Q4wqJ7Z9K/Av5F6kvG9oRq1DOPJuGhGh0nGYjXhXfvUeIibXcvJSgboahOmSNF6dvga2pBWBoNHR0T51/9QqSthvkQTxcb0Kt9i81TbdhKg5PIspTi0usmcen1JAhOK8O0ZKO6lMF3qB5sB24X8oHutszXDWnobgfrrgkLCFq6UXBBP92zgs33uRytQN4a1IhWi7St8GGDM0OkrYYPf1QBF6z8oGsKLwYH8k2W5ZQK3xv2O0la+S0wt68srM9F71p+8N7U1ywbwj7RVL/ti2F+8Gt2iHMgT667VdIvmxaeBWhNse/ERcjZW3lpQfcFfGWDSFuVaHjGHndlVM5On7C+GziTdvNjbLfaqKIpO27Hq8LtsX4kSUHakHUZxFQwIRt4y2nn5tsiD1QgZrH3qG3DdmdBWluazmLT5FGiG9L6coV9QpLWcQELaYm01bGy7GOazw0Z+IQM4k9nOVl2xsOBONvF0f5c2skhn2Hg4Whzl6AKn2N7DXjJTa8WneFAQgsTx8e9OC4KDGCCATCHa8Fmlu2VOQ3IF/TgRIVsUbLnhkhbtxBp6xYibd1CpK1PbgjSlszOIdLWB3dHkbSlc+qItPUBUvVm2SoAIm2dMDZ2c3S7xIdIWy+0HLTAEg8ibb0w+ttoqQeRtm4ony1JpK1biLR1C5H20hA3RCgbly3dlyGoKncgIsPSciwaRMqn7wjATHIGJU+X7fdFpL0kYM7EZvpLd0oA5fsyyFvLHUV0f27gT44/T4Jn6Jj1xcsvibSXxMC/DABozc82080ZKhUSNz9wjozsMtLeDWnmNfVnUT3BEaNSzLoK+FLWYW0MT7f5uJdcH6bj1DKDt3EQzTpOdRp8q3uCXbtV0m7hEkTayyK2yQ4x0rYKUY2w+cGStC+DuHfDRL9krIIjqgHBft0yeDQujOQbw0w3ns5jDYPotBJ/xh1P2TAuN0U6myQTH1gp3YqYSHtp2O0TGiytb41a0ODND8JKYV+Gwt4NalFa6HYhR/cmMmbo5jJqpeLGQ2pE0YQK5KAmaAFzy1YUT5gjixJAz4a0P44yVTqjkkh7Sege0+CRBs+k657EVqugjctLH2SRPWS6wt4N2Fg/5a32U6tNA3gvHX0yjafdPQXKcFP3OAgqrLPYasOStLoP2kiYFqX1pJjsdHGORNrLIkZR/UiAkX1kg0Ocx0Lr0gzel4GR9m4APN6HAYcUHTYqhXdO4IDOQq/jTRX8mWSPBXnv0+I2DjioZyTN4K0e8GRmNYAPi6e8EmnrFiJt3UKkrVuItPUJbMbSQvKxr/rjxgFE0m6P/n5Iwh+N0W37FzcOrvoqCLWgZXTsLjHauqT54KCG3x8jXCXbv9Xw+2OEq+QGKY6vIyUr9/gEU+YAeMfUwtcTYK7i9449bJ3uM/kHAcaoEQVtLN8SvmTYvTBcXzJubxdnVOiSjDDB4gS+TJtdWNYLlPvk26pXQHYSAG9T9J8mzmYycTCXM1loEGf/3OpfMw0xnlzS5V8b2RMU9a9990QNHyKfXhqZdY8hgmLQ1gfJ3pwMrqHIPSiyKGLMpALKf3+N51z09Zvf1nh7bUJFrFuuhAEYw/juw8OlDRXsc9kUtGC1jyzyWZq/w+kEY4WHyCHLhMxvGXc7PHSt4kH9VZcupfatqt0qeKdhox/04b2c4EQ/GOTMoonzi/9DyuWrwZnIfWCMYQYVoCP/WhpUA8ctcUw+Ti1YghpgFIbrUUDB0fxuc+Tf94IKjwK622DG9ABJK/MNuu7cA1nO3SYW5PwgTiBfegdfkuL4SnAygJ9SG5eZgXchZLWCtI4OcL8VD9hb5EjaZUaSFjsYPQP8TWBwUcW7XRvtoM81hz+T4hpsR3aalxa6O4BDNbAoSqsMk29dXwk2iko9BnA1xdk2TR8EaTt0emqhNTJCUdhqwXpqpFMQCTtkzkXTMg3Wlxne3RbdpLZcYCLVm1F77lDDeHJO1oJDmhepdJNUIBc+ckMgEAgEAoFAIJye/wUYy32Aeg4bdgAAAABJRU5ErkJggg==)\n",
    "\n",
    "Another very detailed video explanation on Correlation and Covariance by one of my inspiration - Josh Starmer\n",
    "1. Covariance - https://www.youtube.com/watch?v=qtaqvPAeEJY\n",
    "2. Correlation - https://www.youtube.com/watch?v=xZ_z8KWkhXE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to Refer: \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/01/comprehensive-practical-guide-inferential-statistics-data-science/ - Comprehensive & practical inferential statistics guide for Data Science (most of the above content is from this particular link)\n",
    "\n",
    "https://statisticsbyjim.com/basics/descriptive-inferential-statistics/ - Descriptive vs Inferential Statistics\n",
    "\n",
    "**Video Tutorials**:\n",
    "\n",
    "https://www.youtube.com/watch?v=ZxK7SXURFcM - Inferential Statistics by GreyAtom\n",
    "\n",
    "https://www.youtube.com/watch?v=qBigTkBLU6g&list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9 - Statistics Fundamentals Playlist by Joshua Starmer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
